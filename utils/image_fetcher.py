"""Pexels APIë¥¼ ì‚¬ìš©í•œ AI ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²€ìƒ‰ + Puppeteer ìŠ¤í¬ë¦°ìƒ·"""
import json
import logging
import random
import re
import requests
from datetime import datetime
from typing import Optional
from dataclasses import dataclass
from pathlib import Path

import anthropic

import sys
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
from config.settings import settings
from utils.unique_image import (
    generate_unique_screenshot,
    should_use_screenshot,
    cleanup_old_screenshots
)
from utils.screenshot_advisor import (
    get_screenshot_recommendation,
    validate_screenshot_url,
    get_fallback_url
)

logger = logging.getLogger(__name__)

# ì„¤ì • íŒŒì¼ ê²½ë¡œ
CONFIG_DIR = Path(settings.config_dir)

# =============================================================================
# í‚¤ì›Œë“œë³„ ì˜ë¬¸ ì´ë¯¸ì§€ ê²€ìƒ‰ì–´ ë§¤í•‘ (í™•ì¥íŒ)
# =============================================================================
IMAGE_KEYWORD_MAPPING = {
    # ì¬í…Œí¬/ê¸ˆìœµ
    "ë¹„íŠ¸ì½”ì¸": ["bitcoin cryptocurrency", "bitcoin trading chart", "crypto coins gold", "digital currency blockchain"],
    "ì½”ì¸": ["cryptocurrency trading", "bitcoin digital", "crypto investment", "blockchain technology"],
    "ì•”í˜¸í™”í": ["cryptocurrency market", "bitcoin ethereum", "crypto trading screen", "digital currency"],
    "ì£¼ì‹": ["stock market chart", "trading screen monitor", "investment graph", "stock exchange floor"],
    "íˆ¬ì": ["investment portfolio", "money growth chart", "financial planning", "wealth management"],
    "ì—°ë§ì •ì‚°": ["tax documents calculator", "financial paperwork office", "tax refund money", "accounting spreadsheet"],
    "ì„¸ê¸ˆ": ["tax calculator documents", "financial forms", "tax payment receipt", "accounting office"],
    "ë¶€ë™ì‚°": ["apartment building exterior", "real estate house", "modern home interior", "property keys hand"],
    "ëŒ€ì¶œ": ["bank loan approval", "money lending documents", "credit application", "financial contract signing"],
    "ì²­ì•½": ["apartment construction", "housing complex aerial", "new building apartment", "modern apartment exterior"],
    "ì „ì„¸": ["apartment living room", "house interior modern", "real estate contract", "home keys"],
    "ì›”ì„¸": ["apartment rental", "house keys contract", "modern studio apartment", "rental agreement"],
    "êµ­ë¯¼ì—°ê¸ˆ": ["retirement senior happy", "elderly couple smiling", "pension retirement", "senior citizen lifestyle"],
    "ê±´ê°•ë³´í—˜": ["health insurance card", "medical documents", "hospital healthcare", "insurance paperwork"],
    "ì‹¤ì—…ê¸‰ì—¬": ["job search computer", "career change", "job hunting office", "unemployment office"],
    "ì‹ ìš©ì ìˆ˜": ["credit score report", "credit card finance", "financial documents", "banking app phone"],
    "ì‹ ìš©ì¹´ë“œ": ["credit card payment", "card transaction pos", "shopping wallet", "credit card hand"],
    "ì ê¸ˆ": ["savings piggy bank", "money jar coins", "bank savings account", "financial growth"],
    "ETF": ["stock market monitor", "investment trading", "financial chart analysis", "portfolio management"],
    "ì—°ê¸ˆì €ì¶•": ["retirement planning", "pension fund", "senior couple happy", "financial security"],

    # IT/í…Œí¬
    "ì•„ì´í°": ["iphone smartphone hand", "apple iphone screen", "smartphone technology", "mobile phone white"],
    "ê°¤ëŸ­ì‹œ": ["samsung galaxy phone", "android smartphone", "mobile device screen", "smartphone technology"],
    "ë…¸íŠ¸ë¶": ["laptop computer desk", "macbook workspace", "laptop keyboard typing", "computer screen office"],
    "ë§¥ë¶": ["macbook laptop desk", "apple computer", "laptop workspace coffee", "macbook screen"],
    "AI": ["artificial intelligence robot", "AI technology circuit", "machine learning concept", "digital brain network"],
    "ì¸ê³µì§€ëŠ¥": ["AI robot futuristic", "artificial intelligence", "machine learning data", "technology innovation"],
    "ì±—GPT": ["AI chatbot screen", "artificial intelligence", "computer conversation", "technology innovation"],
    "ìŠ¤ë§ˆíŠ¸í°": ["smartphone hand holding", "mobile phone screen", "smartphone technology", "mobile device"],

    # ì—°ì˜ˆ/ë“œë¼ë§ˆ/ì˜í™”
    "ë“œë¼ë§ˆ": ["tv remote living room", "streaming service screen", "movie watching couch", "television entertainment"],
    "ì˜í™”": ["cinema popcorn movie", "movie theater seats", "film camera production", "cinema screen dark"],
    "ì•„ì´ëŒ": ["concert stage lights", "music performance live", "microphone spotlight", "concert crowd audience"],
    "ì½˜ì„œíŠ¸": ["concert audience lights", "music festival stage", "live performance crowd", "stage spotlight"],
    "BTS": ["concert stage lights", "music performance", "kpop stage", "audience concert"],
    "ì˜ˆëŠ¥": ["tv studio set", "talk show stage", "entertainment studio", "variety show"],
    "ë„·í”Œë¦­ìŠ¤": ["streaming service tv", "netflix watching", "movie night couch", "entertainment screen"],

    # ê±´ê°•/ë‹¤ì´ì–´íŠ¸
    "ë‹¤ì´ì–´íŠ¸": ["healthy salad food", "weight loss fitness", "healthy eating vegetables", "diet meal prep"],
    "ìš´ë™": ["gym workout fitness", "exercise training", "fitness equipment gym", "workout routine"],
    "í—¬ìŠ¤": ["gym fitness equipment", "workout training", "health club exercise", "fitness center"],
    "ì˜ì–‘ì œ": ["vitamin supplements bottle", "health pills capsules", "nutrition supplements", "wellness products"],
    "ê±´ê°•": ["healthy lifestyle nature", "wellness fitness", "healthy living", "active lifestyle outdoor"],
    "ìˆ˜ë©´": ["sleep bedroom peaceful", "sleeping comfortable bed", "restful night bedroom", "peaceful sleep"],
    "íƒˆëª¨": ["hair care products", "scalp treatment", "hair growth", "hair wellness"],

    # ìƒí™œì •ë³´
    "ìš´ì „ë©´í—ˆ": ["driving car interior", "car steering wheel", "driving lesson instructor", "road driving view"],
    "ì—¬í–‰": ["travel vacation beach", "airplane window view", "tourist destination landmark", "vacation luggage"],
    "ë§›ì§‘": ["restaurant food delicious", "gourmet dining table", "food cuisine plate", "restaurant interior"],
    "ì¹´í˜": ["coffee cafe cozy", "cafe interior design", "coffee shop latte", "barista coffee"],
    "ìš”ë¦¬": ["cooking kitchen chef", "food preparation", "home cooking kitchen", "recipe ingredients"],
    "ë‚ ì”¨": ["weather sky clouds", "sunny day outdoor", "rain umbrella", "weather forecast phone"],
    "ìœ¡ì•„": ["parenting baby child", "mother child happy", "family baby care", "parent child love"],
    "ì²­ì†Œ": ["cleaning home organized", "house cleaning supplies", "tidy room interior", "organized home"],
    "ì¸í…Œë¦¬ì–´": ["interior design modern", "living room stylish", "home decoration", "apartment design"],
    "ìë™ì°¨": ["car automobile modern", "driving vehicle road", "car interior dashboard", "modern car exterior"],
    "ìë™ì°¨ë³´í—˜": ["car insurance document", "auto protection safety", "vehicle key hand", "car accident prevention"],
    "ì—¬ê¶Œ": ["passport travel documents", "airport departure board", "international travel", "passport stamps"],

    # ì·¨ì—…/êµìœ¡
    "ì·¨ì—…": ["job interview office", "career success business", "handshake meeting", "professional work"],
    "ë©´ì ‘": ["job interview handshake", "business meeting office", "interview conversation", "career opportunity"],
    "ì´ë ¥ì„œ": ["resume document writing", "job application", "career documents", "CV preparation"],
    "ìê²©ì¦": ["certificate diploma", "achievement award", "professional certification", "graduation success"],
    "ê³µë¬´ì›": ["government building", "public service office", "official work desk", "administrative office"],

    # íŠ¸ë Œë“œ/ê¸°íƒ€
    "íŠ¸ë Œë“œ": ["trending popular culture", "modern lifestyle", "contemporary style", "viral content"],
    "í‚¤ìŠ¤": ["romantic couple", "love relationship", "romance drama", "couple happiness"],
}

# ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ ê²€ìƒ‰ì–´ (í‚¤ì›Œë“œ ë§¤í•‘ ì—†ì„ ë•Œ í´ë°±)
CATEGORY_DEFAULT_KEYWORDS = {
    "ì¬í…Œí¬": ["money finance chart", "investment success", "financial planning office", "business growth"],
    "ITí…Œí¬": ["technology gadget modern", "digital device screen", "innovation tech", "smart technology"],
    "ì—°ì˜ˆ": ["entertainment stage lights", "celebrity event red carpet", "award ceremony", "performance show"],
    "ê±´ê°•": ["health wellness nature", "fitness lifestyle", "healthy living outdoor", "wellness routine"],
    "ìƒí™œì •ë³´": ["daily life tips", "home organization", "practical advice", "lifestyle modern"],
    "ì·¨ì—…êµìœ¡": ["career success office", "education learning", "professional growth", "job interview"],
    "íŠ¸ë Œë“œ": ["trending popular", "modern culture", "contemporary lifestyle", "viral content"]
}


@dataclass
class PexelsImage:
    """Pexels ì´ë¯¸ì§€ ë°ì´í„°"""
    id: int
    url: str
    photographer: str
    alt: str
    width: int
    height: int


class ImageFetcher:
    """Pexels API ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ ê²€ìƒ‰ê¸°"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or settings.pexels_api_key
        self.api_url = settings.pexels_api_url
        self.headers = {
            "Authorization": self.api_key
        }
        # ì¹´í…Œê³ ë¦¬ ì„¤ì • ë¡œë“œ
        self.categories_config = self._load_categories()

    def _load_categories(self) -> dict:
        """ì¹´í…Œê³ ë¦¬ ì„¤ì • ë¡œë“œ"""
        try:
            filepath = CONFIG_DIR / "categories.json"
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"Failed to load categories.json: {e}")
            return {"categories": {}, "image_styles": {}}

    def get_image_style_keywords(self, image_style: str) -> list[str]:
        """ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œ ë°˜í™˜"""
        image_styles = self.categories_config.get("image_styles", {})
        return image_styles.get(image_style, image_styles.get("ai_general", [
            "people lifestyle", "modern urban life", "success growth"
        ]))

    def get_image_count_for_category(self, category_name: str) -> int:
        """
        ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ ë°˜í™˜

        Args:
            category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„

        Returns:
            ì´ë¯¸ì§€ ê°œìˆ˜ (ê¸°ë³¸ê°’ 4)
        """
        categories = self.categories_config.get("categories", {})
        category_info = categories.get(category_name, {})
        return category_info.get("image_count", 4)

    def get_search_keywords_for_topic(self, keyword: str, category_name: str = None) -> list[str]:
        """
        í‚¤ì›Œë“œì— ë§ëŠ” ì˜ë¬¸ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

        Args:
            keyword: í•œê¸€ í‚¤ì›Œë“œ
            category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„ (í´ë°±ìš©)

        Returns:
            ì˜ë¬¸ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
        """
        # 1ìˆœìœ„: í‚¤ì›Œë“œ ì§ì ‘ ë§¤í•‘
        for ko_key, en_keywords in IMAGE_KEYWORD_MAPPING.items():
            if ko_key in keyword:
                logger.info(f"Keyword mapping found: '{keyword}' matches '{ko_key}'")
                return en_keywords

        # 2ìˆœìœ„: ì¹´í…Œê³ ë¦¬ ê¸°ë³¸ ê²€ìƒ‰ì–´
        if category_name and category_name in CATEGORY_DEFAULT_KEYWORDS:
            logger.info(f"Using category default: {category_name}")
            return CATEGORY_DEFAULT_KEYWORDS[category_name]

        # 3ìˆœìœ„: ìµœì¢… í´ë°±
        return ["lifestyle modern", "success achievement", "professional business", "technology innovation"]

    def search_images(
        self,
        keyword: str,
        count: int = 4,
        orientation: str = "landscape",
        category_name: str = None
    ) -> list[PexelsImage]:
        """
        Pexelsì—ì„œ í‚¤ì›Œë“œì— ë§ëŠ” ì´ë¯¸ì§€ ê²€ìƒ‰ (ì¤‘ë³µ ë°©ì§€ í¬í•¨)

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            count: ë°˜í™˜í•  ì´ë¯¸ì§€ ìˆ˜
            orientation: ì´ë¯¸ì§€ ë°©í–¥ (landscape, portrait, square)
            category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„ (í´ë°±ìš©)

        Returns:
            PexelsImage ë¦¬ìŠ¤íŠ¸
        """
        if not self.api_key:
            logger.warning("Pexels API key not configured")
            return []

        try:
            # í‚¤ì›Œë“œì— ë§ëŠ” ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ê¸°
            search_keywords = self.get_search_keywords_for_topic(keyword, category_name)
            print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ê²€ìƒ‰ì–´: '{keyword}' â†’ {search_keywords}")

            images = []
            used_urls = set()  # ì¤‘ë³µ ë°©ì§€ìš©

            # ê° ê²€ìƒ‰ì–´ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰
            for i, search_term in enumerate(search_keywords[:count]):
                params = {
                    "query": search_term,
                    "per_page": 10,  # ì—¬ëŸ¬ ê²°ê³¼ ì¤‘ ëœë¤ ì„ íƒ
                    "orientation": orientation,
                    "size": "medium"
                }

                print(f"  â””â”€ Pexels ê²€ìƒ‰: {search_term}")
                logger.info(f"Searching Pexels: {search_term}")

                response = requests.get(
                    self.api_url,
                    headers=self.headers,
                    params=params,
                    timeout=10
                )
                response.raise_for_status()

                data = response.json()
                photos = data.get("photos", [])

                if photos:
                    # ì¤‘ë³µ ì œì™¸í•˜ê³  ëœë¤ ì„ íƒ
                    available = [p for p in photos if p.get("src", {}).get("medium", "") not in used_urls]

                    if available:
                        # ëœë¤ìœ¼ë¡œ ì„ íƒ
                        photo = random.choice(available)
                        img_url = photo.get("src", {}).get("medium", "")
                        if not img_url:
                            img_url = photo.get("src", {}).get("large", "")

                        print(f"      âœ“ {img_url[:60]}...")

                        image = PexelsImage(
                            id=photo.get("id"),
                            url=img_url,
                            photographer=photo.get("photographer", ""),
                            alt=photo.get("alt", keyword),
                            width=photo.get("width", 800),
                            height=photo.get("height", 600)
                        )
                        images.append(image)
                        used_urls.add(img_url)

                if len(images) >= count:
                    break

            logger.info(f"Found {len(images)} unique images for: {keyword}")
            return images

        except requests.exceptions.RequestException as e:
            logger.error(f"Pexels API error: {e}")
            return []
        except Exception as e:
            logger.error(f"Error fetching images: {e}")
            return []

    def search_images_for_category(
        self,
        keyword: str,
        category_name: str,
        count: int = None
    ) -> list[PexelsImage]:
        """
        ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ì´ë¯¸ì§€ ê²€ìƒ‰ (í‚¤ì›Œë“œ ë§¤í•‘ ìš°ì„ )

        Args:
            keyword: ë¸”ë¡œê·¸ í‚¤ì›Œë“œ
            category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„ (ì¬í…Œí¬, ITí…Œí¬ ë“±)
            count: í•„ìš”í•œ ì´ë¯¸ì§€ ìˆ˜ (Noneì´ë©´ ì¹´í…Œê³ ë¦¬ ì„¤ì • ì‚¬ìš©)

        Returns:
            PexelsImage ë¦¬ìŠ¤íŠ¸
        """
        # ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ ì ìš©
        if count is None:
            count = self.get_image_count_for_category(category_name)

        return self.search_images(
            keyword=keyword,
            count=count,
            category_name=category_name
        )

    def download_image(self, url: str) -> Optional[bytes]:
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            return response.content
        except Exception as e:
            logger.error(f"Error downloading image: {e}")
            return None

    def verify_image_url(self, url: str) -> bool:
        """
        ì´ë¯¸ì§€ URLì´ ìœ íš¨í•œì§€ ê²€ì¦

        Args:
            url: ê²€ì¦í•  ì´ë¯¸ì§€ URL

        Returns:
            URLì´ ìœ íš¨í•˜ë©´ True
        """
        if not url or not url.startswith('http'):
            return False

        try:
            response = requests.head(url, timeout=10, allow_redirects=True)
            if response.status_code == 200:
                content_type = response.headers.get('Content-Type', '')
                if 'image' in content_type:
                    return True
            # HEAD ì‹¤íŒ¨ ì‹œ GETìœ¼ë¡œ ì¬ì‹œë„ (ì¼ë¶€ ì„œë²„ëŠ” HEAD ë¯¸ì§€ì›)
            response = requests.get(url, timeout=10, stream=True)
            response.close()
            return response.status_code == 200
        except Exception as e:
            logger.warning(f"URL verification failed for {url[:50]}...: {e}")
            return False

    def generate_image_html(
        self,
        image: PexelsImage,
        keyword: str,
        caption: str = None
    ) -> str:
        """
        ì´ë¯¸ì§€ HTML ìƒì„±

        Args:
            image: PexelsImage ê°ì²´
            keyword: í‚¤ì›Œë“œ (alt íƒœê·¸ìš©)
            caption: ì´ë¯¸ì§€ ìº¡ì…˜

        Returns:
            HTML ë¬¸ìì—´
        """
        if caption is None:
            caption = f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€"

        alt_text = f"{keyword} - {image.alt}" if image.alt else keyword

        html = f'''
<figure style="text-align: center; margin: 30px 0;">
    <img src="{image.url}"
         alt="{alt_text}"
         style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);"
         loading="lazy" />
    <figcaption style="margin-top: 10px; color: #666; font-size: 14px;">
        {caption} (Photo by {image.photographer} on Pexels)
    </figcaption>
</figure>
'''
        return html

    # =========================================================================
    # AI ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²€ìƒ‰ ë©”ì„œë“œ
    # =========================================================================

    def extract_image_contexts(self, content: str) -> list:
        """
        ê¸€ì—ì„œ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            content: HTML ì½˜í…ì¸ 

        Returns:
            ì´ë¯¸ì§€ ìœ„ì¹˜ì™€ ì»¨í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        contexts = []

        # 1ìˆœìœ„: IMG_CONTEXT ì£¼ì„ ì‚¬ìš©
        pattern = r'<!-- IMG_CONTEXT: (.+?) -->\s*\[IMAGE_(\d+)\]'
        matches = re.findall(pattern, content)

        if matches:
            for context, num in matches:
                contexts.append({
                    'position': int(num),
                    'context': context.strip(),
                    'source': 'comment'
                })
            logger.info(f"Found {len(contexts)} IMG_CONTEXT comments")
        else:
            # 2ìˆœìœ„: [IMAGE] ì£¼ë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì• 200ì)
            pattern = r'(.{50,300}?)\[IMAGE_(\d+)\]'
            matches = re.findall(pattern, content, re.DOTALL)

            for surrounding_text, num in matches:
                # HTML íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                clean_text = re.sub(r'<[^>]+>', ' ', surrounding_text)
                clean_text = re.sub(r'\s+', ' ', clean_text).strip()

                contexts.append({
                    'position': int(num),
                    'context': clean_text[-200:],  # ë§ˆì§€ë§‰ 200ì
                    'source': 'surrounding'
                })
            logger.info(f"Extracted {len(contexts)} contexts from surrounding text")

        # ì •ë ¬
        contexts.sort(key=lambda x: x['position'])
        return contexts

    def generate_image_search_query(self, context: str, keyword: str) -> str:
        """
        AIë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ì–´ ìƒì„±

        Args:
            context: ì„¹ì…˜ ì»¨í…ìŠ¤íŠ¸ (IMG_CONTEXT ë˜ëŠ” ì£¼ë³€ í…ìŠ¤íŠ¸)
            keyword: ë¸”ë¡œê·¸ í‚¤ì›Œë“œ

        Returns:
            ì˜ë¬¸ ì´ë¯¸ì§€ ê²€ìƒ‰ì–´
        """
        try:
            client = anthropic.Anthropic(api_key=settings.claude_api_key)

            prompt = f"""ë‹¤ìŒ ë¸”ë¡œê·¸ ê¸€ì˜ í•œ ì„¹ì…˜ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì— ì–´ìš¸ë¦¬ëŠ” Pexels ì´ë¯¸ì§€ ê²€ìƒ‰ì–´ë¥¼ ì˜ë¬¸ìœ¼ë¡œ 1ê°œë§Œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

[ë¸”ë¡œê·¸ ì£¼ì œ]: {keyword}
[ì„¹ì…˜ ë‚´ìš©]: {context}

ê·œì¹™:
1. ì˜ë¬¸ ê²€ìƒ‰ì–´ë§Œ ì¶œë ¥ (2~4ë‹¨ì–´)
2. ì‹¤ì œ ì¸ë¬¼/ì—°ì˜ˆì¸ ì´ë¦„ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€
3. Pexelsì—ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ í‚¤ì›Œë“œ
4. ì¶”ìƒì ì¸ ê°œë…ë³´ë‹¤ êµ¬ì²´ì ì¸ ì‚¬ë¬¼/ì¥ë©´
5. ê²€ìƒ‰ì–´ë§Œ ì¶œë ¥, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´

ì˜ˆì‹œ ì¶œë ¥:
cryptocurrency trading chart
office desk documents
fitness workout gym
smartphone technology modern"""

            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=50,
                messages=[{"role": "user", "content": prompt}]
            )

            search_query = response.content[0].text.strip()

            # ì•ˆì „ ê²€ì¦
            if re.search(r'[ê°€-í£]', search_query) or len(search_query) > 50:
                logger.warning(f"Invalid AI query: {search_query}, using fallback")
                return self._get_fallback_query(keyword)

            # ì¤„ë°”ê¿ˆì´ë‚˜ ì—¬ëŸ¬ ì¤„ì´ë©´ ì²« ì¤„ë§Œ
            search_query = search_query.split('\n')[0].strip()

            logger.info(f"AI generated query: '{search_query}'")
            return search_query

        except Exception as e:
            logger.error(f"AI query generation failed: {e}")
            return self._get_fallback_query(keyword)

    def _get_fallback_query(self, keyword: str) -> str:
        """í´ë°± ê²€ìƒ‰ì–´ ë°˜í™˜"""
        # ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤í•‘ì—ì„œ ì°¾ê¸°
        for ko_key, en_keywords in IMAGE_KEYWORD_MAPPING.items():
            if ko_key in keyword:
                return random.choice(en_keywords)
        return "modern lifestyle professional"

    def search_pexels_single(self, query: str, per_page: int = 5) -> list:
        """
        Pexels ë‹¨ì¼ ê²€ìƒ‰ì–´ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰

        Args:
            query: ì˜ë¬¸ ê²€ìƒ‰ì–´
            per_page: ê²°ê³¼ ê°œìˆ˜

        Returns:
            Pexels API ì‘ë‹µì˜ photos ë¦¬ìŠ¤íŠ¸
        """
        if not self.api_key:
            return []

        try:
            params = {
                "query": query,
                "per_page": per_page,
                "orientation": "landscape",
                "size": "medium"
            }

            response = requests.get(
                self.api_url,
                headers=self.headers,
                params=params,
                timeout=10
            )
            response.raise_for_status()

            data = response.json()
            return data.get("photos", [])

        except Exception as e:
            logger.error(f"Pexels search failed for '{query}': {e}")
            return []

    def fetch_contextual_images(self, content: str, keyword: str) -> dict:
        """
        ê¸€ ë‚´ìš© ë¶„ì„ í›„ ë§¥ë½ì— ë§ëŠ” ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°

        Args:
            content: HTML ì½˜í…ì¸ 
            keyword: ë¸”ë¡œê·¸ í‚¤ì›Œë“œ

        Returns:
            {IMAGE_1: {url, alt, caption, search_query}, ...} ë”•ì…”ë„ˆë¦¬
        """
        print(f"\nğŸ¤– AI ê¸°ë°˜ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹œì‘: '{keyword}'")

        contexts = self.extract_image_contexts(content)
        images = {}
        used_urls = set()

        if not contexts:
            logger.warning("No image contexts found, using fallback")
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            return self._fallback_images(keyword, count=4)

        for ctx in contexts:
            position = ctx['position']
            context_text = ctx['context']

            # AIë¡œ ê²€ìƒ‰ì–´ ìƒì„±
            if ctx['source'] == 'comment':
                # IMG_CONTEXT ì£¼ì„ì€ ì´ë¯¸ ì˜ë¬¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                search_query = context_text if self._is_english(context_text) else self.generate_image_search_query(context_text, keyword)
            else:
                search_query = self.generate_image_search_query(context_text, keyword)

            print(f"  ğŸ–¼ï¸ IMAGE_{position}: {search_query}")

            # Pexels ê²€ìƒ‰
            photos = self.search_pexels_single(search_query, per_page=8)

            if photos:
                # ë¯¸ì‚¬ìš© ì´ë¯¸ì§€ ì¤‘ ëœë¤ ì„ íƒ
                for photo in photos:
                    img_url = photo.get("src", {}).get("large") or photo.get("src", {}).get("medium", "")
                    if img_url and img_url not in used_urls:
                        images[f"IMAGE_{position}"] = {
                            'url': img_url,
                            'alt': f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€",
                            'photographer': photo.get('photographer', 'Unknown'),
                            'search_query': search_query
                        }
                        used_urls.add(img_url)
                        print(f"      âœ“ {img_url[:50]}...")
                        break

            # ê²°ê³¼ ì—†ìœ¼ë©´ í´ë°± ê²€ìƒ‰
            if f"IMAGE_{position}" not in images:
                fallback_query = self._get_fallback_query(keyword)
                print(f"      âš ï¸ í´ë°± ê²€ìƒ‰: {fallback_query}")
                fallback_photos = self.search_pexels_single(fallback_query, per_page=5)

                if fallback_photos:
                    for photo in fallback_photos:
                        img_url = photo.get("src", {}).get("large") or photo.get("src", {}).get("medium", "")
                        if img_url and img_url not in used_urls:
                            images[f"IMAGE_{position}"] = {
                                'url': img_url,
                                'alt': f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€",
                                'photographer': photo.get('photographer', 'Unknown'),
                                'search_query': f"fallback: {fallback_query}"
                            }
                            used_urls.add(img_url)
                            break

        print(f"  ğŸ“¸ ì´ {len(images)}ê°œ ì´ë¯¸ì§€ í™•ë³´\n")
        return images

    def _is_english(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ ì˜ë¬¸ì¸ì§€ í™•ì¸"""
        return not bool(re.search(r'[ê°€-í£]', text))

    def _fallback_images(self, keyword: str, count: int = 4) -> dict:
        """í´ë°± ì´ë¯¸ì§€ ê²€ìƒ‰"""
        images = {}
        used_urls = set()
        search_keywords = self.get_search_keywords_for_topic(keyword)

        for i in range(1, count + 1):
            query = search_keywords[(i - 1) % len(search_keywords)]
            photos = self.search_pexels_single(query, per_page=5)

            if photos:
                for photo in photos:
                    img_url = photo.get("src", {}).get("large") or photo.get("src", {}).get("medium", "")
                    if img_url and img_url not in used_urls:
                        images[f"IMAGE_{i}"] = {
                            'url': img_url,
                            'alt': f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€",
                            'photographer': photo.get('photographer', 'Unknown'),
                            'search_query': query
                        }
                        used_urls.add(img_url)
                        break

        return images

    # =========================================================================
    # Phase 3: í˜¼í•© ì´ë¯¸ì§€ ì‹œìŠ¤í…œ (Puppeteer ìŠ¤í¬ë¦°ìƒ· + Pexels)
    # =========================================================================

    def upload_to_wordpress_media(self, local_path: str, alt_text: str = None) -> Optional[str]:
        """
        ë¡œì»¬ ì´ë¯¸ì§€ë¥¼ ì›Œë“œí”„ë ˆìŠ¤ ë¯¸ë””ì–´ì— ì—…ë¡œë“œ

        Args:
            local_path: ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
            alt_text: ëŒ€ì²´ í…ìŠ¤íŠ¸

        Returns:
            ì—…ë¡œë“œëœ ì´ë¯¸ì§€ URL ë˜ëŠ” None
        """
        import os
        import base64

        if not os.path.exists(local_path):
            logger.warning(f"Local file not found: {local_path}")
            return None

        try:
            # ì¸ì¦ í—¤ë”
            credentials = f"{settings.wp_user}:{settings.wp_app_password}"
            token = base64.b64encode(credentials.encode()).decode('utf-8')

            headers = {
                'Authorization': f'Basic {token}',
                'Content-Disposition': f'attachment; filename={os.path.basename(local_path)}',
                'Content-Type': 'image/png'
            }

            with open(local_path, 'rb') as img_file:
                response = requests.post(
                    f"{settings.wp_url}/wp-json/wp/v2/media",
                    headers=headers,
                    data=img_file,
                    timeout=60
                )

            if response.status_code == 201:
                media_url = response.json().get('source_url')
                logger.info(f"WordPress upload success: {media_url}")
                print(f"âœ… ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œ ì™„ë£Œ: {media_url[:50]}...")

                # ì—…ë¡œë“œëœ URL ê²€ì¦
                if self.verify_image_url(media_url):
                    return media_url
                else:
                    logger.warning(f"Uploaded URL verification failed: {media_url}")
                    print(f"âš ï¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ URL ì ‘ê·¼ ë¶ˆê°€, ì¬ì‹œë„ í•„ìš”")
                    return None
            else:
                logger.warning(f"WordPress upload failed: {response.status_code} - {response.text[:200]}")
                return None

        except Exception as e:
            logger.error(f"Upload error: {e}")
            return None

    def _capture_dynamic_screenshot(self, url: str, site_name: str, overlay_text: str) -> Optional[str]:
        """
        AIê°€ ì¶”ì²œí•œ ë™ì  URLë¡œ ìŠ¤í¬ë¦°ìƒ· ìº¡ì³

        Args:
            url: ìŠ¤í¬ë¦°ìƒ·í•  URL
            site_name: ì‚¬ì´íŠ¸ ì´ë¦„
            overlay_text: ì˜¤ë²„ë ˆì´ í…ìŠ¤íŠ¸

        Returns:
            ìŠ¤í¬ë¦°ìƒ· íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
        """
        import subprocess
        import os
        import random

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        random_suffix = random.randint(1000, 9999)
        output_path = f"temp_screenshots/ai_screenshot_{timestamp}_{random_suffix}.png"

        # ë””ë ‰í† ë¦¬ í™•ì¸
        os.makedirs("temp_screenshots", exist_ok=True)

        script_path = Path(__file__).resolve().parent / "screenshot_generator.js"

        cmd = [
            'node', str(script_path),
            '--url', url,
            '--output', output_path,
            '--text', overlay_text
        ]

        try:
            print(f"  ğŸ“¸ ë™ì  ìŠ¤í¬ë¦°ìƒ· ìº¡ì³ ì¤‘: {url[:50]}...")
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60,
                cwd=str(Path(__file__).resolve().parent.parent)
            )

            if result.returncode == 0:
                # ì¶œë ¥ì—ì„œ ìµœì¢… íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
                for line in result.stdout.strip().split('\n'):
                    if line.startswith('RESULT:'):
                        final_path = line.replace('RESULT:', '').strip()
                        if final_path != 'FAILED' and os.path.exists(final_path):
                            logger.info(f"Dynamic screenshot captured: {final_path}")
                            return final_path

                # RESULT ì—†ì´ output_pathê°€ ì¡´ì¬í•˜ë©´ ì‚¬ìš©
                if os.path.exists(output_path):
                    logger.info(f"Dynamic screenshot captured: {output_path}")
                    return output_path

                # ì˜¤ë²„ë ˆì´ ë²„ì „ í™•ì¸
                overlay_path = output_path.replace('.png', '_overlay.png')
                if os.path.exists(overlay_path):
                    logger.info(f"Dynamic screenshot with overlay: {overlay_path}")
                    return overlay_path

            logger.warning(f"Dynamic screenshot failed: {result.stderr[:200]}")
            return None

        except subprocess.TimeoutExpired:
            logger.warning("Dynamic screenshot timeout (60s)")
            return None
        except FileNotFoundError:
            logger.warning("Node.js not installed or script not found")
            return None
        except Exception as e:
            logger.error(f"Dynamic screenshot error: {e}")
            return None

    def fetch_mixed_images(
        self,
        content: str,
        keyword: str,
        category: str,
        count: int = 4
    ) -> dict:
        """
        AI íŒë‹¨ ê¸°ë°˜ Pexels + ìŠ¤í¬ë¦°ìƒ· í˜¼í•© ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°

        1. AIê°€ ìŠ¤í¬ë¦°ìƒ· í•„ìš” ì—¬ë¶€ ë° URL ë™ì  ì¶”ì²œ
        2. ë‚˜ë¨¸ì§€ëŠ” AI ê¸°ë°˜ Pexels ê²€ìƒ‰

        Args:
            content: HTML ì½˜í…ì¸  (IMG_CONTEXT ì¶”ì¶œìš©)
            keyword: ë¸”ë¡œê·¸ í‚¤ì›Œë“œ
            category: ì¹´í…Œê³ ë¦¬ ì´ë¦„
            count: í•„ìš”í•œ ì´ë¯¸ì§€ ìˆ˜

        Returns:
            {IMAGE_1: {url, alt, ...}, ...} ë”•ì…”ë„ˆë¦¬
        """
        print(f"\nğŸ–¼ï¸ AI ê¸°ë°˜ ì´ë¯¸ì§€ ì‹œìŠ¤í…œ ì‹œì‘: '{keyword}' (ì¹´í…Œê³ ë¦¬: {category})")

        images = {}
        used_urls = set()
        screenshot_used = False

        # ì˜¤ë˜ëœ ìŠ¤í¬ë¦°ìƒ· ì •ë¦¬
        cleanup_old_screenshots()

        # 1. AIì—ê²Œ ìŠ¤í¬ë¦°ìƒ· í•„ìš” ì—¬ë¶€ ì§ˆë¬¸
        screenshot_rec = get_screenshot_recommendation(keyword, category)

        if screenshot_rec.get("need_screenshot"):
            url = screenshot_rec.get("url")
            site_name = screenshot_rec.get("site_name", keyword)

            # URL ê²€ì¦
            if url and validate_screenshot_url(url):
                print(f"  ğŸ“¸ AI ì¶”ì²œ URLë¡œ ìŠ¤í¬ë¦°ìƒ· ì‹œë„: {url}")
                overlay_text = f"{site_name} ({datetime.now().strftime('%Y.%m.%d')})"

                # ë™ì  URL ìŠ¤í¬ë¦°ìƒ· ìº¡ì³
                screenshot_path = self._capture_dynamic_screenshot(url, site_name, overlay_text)

                if screenshot_path:
                    # ì›Œë“œí”„ë ˆìŠ¤ì— ì—…ë¡œë“œ
                    uploaded_url = self.upload_to_wordpress_media(
                        screenshot_path,
                        alt_text=f"{keyword} ì‹¤ì‹œê°„ ì •ë³´"
                    )

                    if uploaded_url:
                        images["IMAGE_1"] = {
                            'url': uploaded_url,
                            'alt': f"{keyword} ì‹¤ì‹œê°„ ì •ë³´",
                            'photographer': "ìë™ ìº¡ì³",
                            'search_query': f"screenshot: {url}",
                            'type': 'screenshot',
                            'site_name': site_name
                        }
                        used_urls.add(uploaded_url)
                        screenshot_used = True
                        print(f"  âœ… AI ì¶”ì²œ ìŠ¤í¬ë¦°ìƒ· ì¶”ê°€ (IMAGE_1)")
                    else:
                        print(f"  âš ï¸ ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œ ì‹¤íŒ¨, Pexelsë¡œ ëŒ€ì²´")
                else:
                    print(f"  âš ï¸ ìŠ¤í¬ë¦°ìƒ· ìƒì„± ì‹¤íŒ¨, í´ë°± ì‹œë„")

                    # í´ë°±: ê¸°ì¡´ í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤í¬ë¦°ìƒ·
                    if should_use_screenshot(keyword, category):
                        fallback_path = generate_unique_screenshot(
                            keyword,
                            f"{keyword} ìµœì‹  ì •ë³´ ({datetime.now().strftime('%Y.%m.%d')})"
                        )
                        if fallback_path:
                            uploaded_url = self.upload_to_wordpress_media(
                                fallback_path,
                                alt_text=f"{keyword} ì‹¤ì‹œê°„ ì •ë³´"
                            )
                            if uploaded_url:
                                images["IMAGE_1"] = {
                                    'url': uploaded_url,
                                    'alt': f"{keyword} ì‹¤ì‹œê°„ ì •ë³´",
                                    'photographer': "ìë™ ìº¡ì³",
                                    'search_query': f"screenshot: {keyword}",
                                    'type': 'screenshot'
                                }
                                used_urls.add(uploaded_url)
                                screenshot_used = True
                                print(f"  âœ… í´ë°± ìŠ¤í¬ë¦°ìƒ· ì¶”ê°€ (IMAGE_1)")
            else:
                print(f"  âš ï¸ URL ê²€ì¦ ì‹¤íŒ¨: {url}, í´ë°± ì‹œë„")

                # í´ë°± URL í™•ì¸
                fallback = get_fallback_url(keyword)
                if fallback.get("url"):
                    print(f"  ğŸ”„ í´ë°± URL ì‚¬ìš©: {fallback['url']}")
                    fallback_path = generate_unique_screenshot(
                        keyword,
                        f"{keyword} ìµœì‹  ì •ë³´ ({datetime.now().strftime('%Y.%m.%d')})"
                    )
                    if fallback_path:
                        uploaded_url = self.upload_to_wordpress_media(
                            fallback_path,
                            alt_text=f"{keyword} ì‹¤ì‹œê°„ ì •ë³´"
                        )
                        if uploaded_url:
                            images["IMAGE_1"] = {
                                'url': uploaded_url,
                                'alt': f"{keyword} ì‹¤ì‹œê°„ ì •ë³´",
                                'photographer': "ìë™ ìº¡ì³",
                                'search_query': f"screenshot: {keyword}",
                                'type': 'screenshot'
                            }
                            used_urls.add(uploaded_url)
                            screenshot_used = True
                            print(f"  âœ… í´ë°± ìŠ¤í¬ë¦°ìƒ· ì¶”ê°€ (IMAGE_1)")
        else:
            print(f"  â„¹ï¸ AI íŒë‹¨: ìŠ¤í¬ë¦°ìƒ· ë¶ˆí•„ìš” â†’ Pexelsë§Œ ì‚¬ìš©")

        # 2. ë‚˜ë¨¸ì§€: AI ê¸°ë°˜ Pexels ì´ë¯¸ì§€
        # ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        contexts = self.extract_image_contexts(content)
        start_index = 2 if screenshot_used else 1

        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰
        if contexts:
            for ctx in contexts:
                position = ctx['position']

                # ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ì´ë¯¸ ì±„ì›Œì§„ ê²½ìš° ìŠ¤í‚µ
                if f"IMAGE_{position}" in images:
                    continue

                context_text = ctx['context']

                # AIë¡œ ê²€ìƒ‰ì–´ ìƒì„±
                if ctx['source'] == 'comment':
                    search_query = context_text if self._is_english(context_text) else self.generate_image_search_query(context_text, keyword)
                else:
                    search_query = self.generate_image_search_query(context_text, keyword)

                print(f"  ğŸ–¼ï¸ IMAGE_{position}: {search_query}")

                # Pexels ê²€ìƒ‰
                photos = self.search_pexels_single(search_query, per_page=8)

                if photos:
                    for photo in photos:
                        img_url = photo.get("src", {}).get("large") or photo.get("src", {}).get("medium", "")
                        if img_url and img_url not in used_urls:
                            images[f"IMAGE_{position}"] = {
                                'url': img_url,
                                'alt': f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€",
                                'photographer': photo.get('photographer', 'Unknown'),
                                'search_query': search_query,
                                'type': 'pexels'
                            }
                            used_urls.add(img_url)
                            print(f"      âœ“ {img_url[:50]}...")
                            break

                # ê²°ê³¼ ì—†ìœ¼ë©´ í´ë°±
                if f"IMAGE_{position}" not in images:
                    fallback_query = self._get_fallback_query(keyword)
                    print(f"      âš ï¸ í´ë°± ê²€ìƒ‰: {fallback_query}")
                    fallback_photos = self.search_pexels_single(fallback_query, per_page=5)

                    if fallback_photos:
                        for photo in fallback_photos:
                            img_url = photo.get("src", {}).get("large") or photo.get("src", {}).get("medium", "")
                            if img_url and img_url not in used_urls:
                                images[f"IMAGE_{position}"] = {
                                    'url': img_url,
                                    'alt': f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€",
                                    'photographer': photo.get('photographer', 'Unknown'),
                                    'search_query': f"fallback: {fallback_query}",
                                    'type': 'pexels'
                                }
                                used_urls.add(img_url)
                                break

        # 3. ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
        remaining_count = count - len(images)
        if remaining_count > 0:
            print(f"  ğŸ” ì¶”ê°€ Pexels ì´ë¯¸ì§€ {remaining_count}ê°œ ê²€ìƒ‰ ì¤‘...")
            search_keywords = self.get_search_keywords_for_topic(keyword)

            for i in range(remaining_count):
                # ë‹¤ìŒ ì´ë¯¸ì§€ ë²ˆí˜¸ ê²°ì •
                next_position = start_index + i
                while f"IMAGE_{next_position}" in images:
                    next_position += 1

                query = search_keywords[i % len(search_keywords)]
                print(f"  ğŸ–¼ï¸ IMAGE_{next_position}: {query}")

                photos = self.search_pexels_single(query, per_page=8)

                if photos:
                    for photo in photos:
                        img_url = photo.get("src", {}).get("large") or photo.get("src", {}).get("medium", "")
                        if img_url and img_url not in used_urls:
                            images[f"IMAGE_{next_position}"] = {
                                'url': img_url,
                                'alt': f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€",
                                'photographer': photo.get('photographer', 'Unknown'),
                                'search_query': query,
                                'type': 'pexels'
                            }
                            used_urls.add(img_url)
                            print(f"      âœ“ {img_url[:50]}...")
                            break

        # í†µê³„
        screenshot_count = sum(1 for img in images.values() if img.get('type') == 'screenshot')
        pexels_count = sum(1 for img in images.values() if img.get('type') == 'pexels')
        print(f"\n  ğŸ“Š ì´ë¯¸ì§€ í†µê³„: ì´ {len(images)}ê°œ (ìŠ¤í¬ë¦°ìƒ·: {screenshot_count}, Pexels: {pexels_count})")

        return images


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    logging.basicConfig(level=logging.INFO)
    fetcher = ImageFetcher()

    # ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("=== ì¬í…Œí¬ ì¹´í…Œê³ ë¦¬ (ì—°ë§ì •ì‚°) ===")
    images = fetcher.search_images_for_category("ì—°ë§ì •ì‚°", "ì¬í…Œí¬", count=4)
    for i, img in enumerate(images, 1):
        print(f"{i}. {img.url[:50]}... by {img.photographer}")

    print("\n=== ITí…Œí¬ ì¹´í…Œê³ ë¦¬ (ì•„ì´í°) ===")
    images = fetcher.search_images_for_category("ì•„ì´í°16", "ITí…Œí¬", count=4)
    for i, img in enumerate(images, 1):
        print(f"{i}. {img.url[:50]}... by {img.photographer}")

    print("\n=== ì—°ì˜ˆ ì¹´í…Œê³ ë¦¬ (BTS) ===")
    images = fetcher.search_images_for_category("BTS", "ì—°ì˜ˆ", count=4)
    for i, img in enumerate(images, 1):
        print(f"{i}. {img.url[:50]}... by {img.photographer}")
